hyperparameters:
  train_file: dataset/train_set.txt  # Path to the txt for training files
  dev_file: dataset/dev_set.txt  # Path to the txt for dev files
  test_file: dataset/test_set.txt  # Path to the txt for testing files
  graph_type: 8 # We recommend to always use this graph alternative. Check dataset/alternatives.py if you want to play with others
  gnn_net: gat  # Options : gat, mpnn, rgcn (mpnn consumes a lot of gpu memory)
  epochs: 2300  # Epochs
  patience: 6  # For early stopping
  batch_size: 5  # Batch size
  num_channels: 35  # These are the number of channels to the CNN input (GNN output)
  num_hidden: [95, 71, 62, 57, 45, 35]  # Number of neurons of hidden layers
  heads: [34, 28, 22, 15, 13, 10]  # Only for gat network (same number of heads as num_hidden)
  residual: False  # Residual connections in the CNN
  lr: 0.00005  # Learning rate
  weight_decay: 1.e-11 # Weight decay
  nonlinearity: elu  # Activation of the hidden layers GNN
  final_activation: relu  # Activation of the output layer GNN
  nonlinearity_cnn: leaky_relu  # Activation of the hidden layers CNN
  final_activation_cnn: tanh  # Activation of the output layer CNN
  in_drop: 0.  # This only affect to the GAT network
  alpha: 0.2088642717278257  # This only affect to the GAT network
  attn_drop: 0.  # This only affect to the GAT network
  cuda: True  # Set it to false if you want to run on CPU